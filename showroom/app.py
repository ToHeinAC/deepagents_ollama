# Generated by Antigravity [Forge: Gemini 3.0] | Spec: [Architect: Opus 4.5]
"""Deep Researcher Streamlit Application.

A web interface for the local deep researcher using LangChain's deepagents framework.
Features real-time task tracking, step visualization, and quality monitoring.

Run with: streamlit run app.py --server.port 8508
"""

import streamlit as st
import os
import sys
import time
import threading
import signal
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# Import memory management utilities
try:
    from memory_utils import clear_cuda_memory, get_memory_stats
except ImportError:
    # Fallback if module not found
    import gc
    def clear_cuda_memory(verbose=True):
        gc.collect()
        if verbose:
            print("[MEMORY] Garbage collection completed (fallback)")
    def get_memory_stats():
        return None

# Load environment variables
load_dotenv()

# Add current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Use LangGraph-based agent (works reliably with Ollama)
from agent import get_agent, get_agent_config

# Page configuration
st.set_page_config(
    page_title="Deep Researcher v0.1",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better UI
st.markdown("""
<style>
    .stProgress > div > div > div > div {
        background-color: #4CAF50;
    }
    .step-indicator {
        padding: 10px;
        border-radius: 5px;
        margin: 5px 0;
    }
    .step-current {
        background-color: #2196F3;
        color: white;
    }
    .step-complete {
        background-color: #4CAF50;
        color: white;
    }
    .step-pending {
        background-color: #9E9E9E;
        color: white;
    }
    .warning-banner {
        background-color: #FF9800;
        color: white;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)


def initialize_session_state():
    """Initialize all session state variables."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "current_phase" not in st.session_state:
        st.session_state.current_phase = "input"  # input, research, complete
    
    if "research_query" not in st.session_state:
        st.session_state.research_query = None
    
    if "todos" not in st.session_state:
        st.session_state.todos = []
    
    if "current_step" not in st.session_state:
        st.session_state.current_step = None
    
    if "step_history" not in st.session_state:
        st.session_state.step_history = []
    
    if "iteration_count" not in st.session_state:
        st.session_state.iteration_count = 0
    
    if "max_iterations_reached" not in st.session_state:
        st.session_state.max_iterations_reached = False
    
    if "final_report" not in st.session_state:
        st.session_state.final_report = None
    
    if "agent_files" not in st.session_state:
        st.session_state.agent_files = {}
    
    if "subagent_activity" not in st.session_state:
        st.session_state.subagent_activity = []
    
    if "research_steps" not in st.session_state:
        st.session_state.research_steps = []  # Store detailed research steps for display
    
    if "research_progress" not in st.session_state:
        st.session_state.research_progress = {}  # Persist progress across refreshes
    
    if "early_termination_enabled" not in st.session_state:
        st.session_state.early_termination_enabled = True


def render_sidebar():
    """Render the sidebar with configuration and debug info."""
    with st.sidebar:
        st.title("‚öôÔ∏è Configuration")
        
        config = get_agent_config()
        
        # Basic Model Info (always visible)
        st.write(f"ü§ñ **{config['model']}** @ `{config['base_url']}`")
        
        # Timeout & Limits Settings
        with st.expander("‚è±Ô∏è Timeouts & Limits", expanded=True):
            stream_timeout = st.slider("Session Timeout (min)", 5, 60, 30, help="Max time for entire research session")
            os.environ["AGENT_STREAM_TIMEOUT_S"] = str(stream_timeout * 60)
            
            model_timeout = st.slider("Model Timeout (sec)", 30, 600, 300, help="Max time per Ollama model call")
            os.environ["OLLAMA_TIMEOUT_S"] = str(model_timeout)
            
            tavily_timeout = st.slider("Search Timeout (sec)", 10, 60, 30, help="Max time per web search")
            os.environ["TAVILY_SEARCH_TIMEOUT_S"] = str(tavily_timeout)
            
            max_iterations = st.slider("Max Iterations", 20, 200, config['recursion_limit'], help="Max agent-tool cycles")
            os.environ["RECURSION_LIMIT"] = str(max_iterations)
        
        # Research Quality Settings
        with st.expander("üéØ Research Quality"):
            st.session_state.early_termination_enabled = st.checkbox(
                "Smart Early Stop", 
                value=st.session_state.early_termination_enabled,
                help="Stop when sufficient research quality is reached"
            )
            
            st.checkbox(
                "Force Final Answer", 
                value=True,
                help="Auto-submit when research thresholds met (always enabled)",
                disabled=True
            )
        
        # Current Session Status
        with st.expander("üìä Session Status", expanded=True):
            st.write(f"**Phase:** {st.session_state.current_phase.upper()}")
            st.write(f"**Iterations:** {st.session_state.iteration_count}")
            
            if st.session_state.max_iterations_reached:
                st.write("**Status:** ‚ö†Ô∏è MAX REACHED")
                st.warning("‚ö†Ô∏è Max iterations reached!")
            else:
                st.write("**Status:** ‚úÖ ACTIVE")
            
            # Show termination reason if available
            if hasattr(st.session_state, 'termination_reason') and st.session_state.termination_reason:
                st.write(f"**Termination Reason:** {st.session_state.termination_reason}")
                if st.session_state.termination_reason.startswith("‚ö†Ô∏è"):
                    st.warning(st.session_state.termination_reason)
        
        # Memory & System Info
        mem_stats = get_memory_stats()
        if mem_stats:
            with st.expander("üíæ System Resources"):
                if mem_stats.get("backend") == "cuda":
                    st.write(f"üî• GPU: {mem_stats.get('allocated_mb', 0):.0f}MB allocated, {mem_stats.get('free_mb', 0):.0f}MB free")
                else:
                    st.write("üíª CPU Memory: Active")
        
        # Current Tasks (only during research)
        if st.session_state.todos and st.session_state.current_phase == "research":
            with st.expander("üìã Current Tasks", expanded=True):
                for todo in st.session_state.todos:
                    status_emoji = {"pending": "‚è≥", "in_progress": "üîÑ", "complete": "‚úÖ"}.get(todo["status"], "‚ùì")
                    st.write(f"{status_emoji} {todo['title']}")
        
        # Controls
        with st.expander("üîß Controls"):
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Clear Progress", help="Clear cached research progress"):
                    if "research_progress" in st.session_state:
                        del st.session_state.research_progress
                    st.success("Progress cleared!")
                    st.rerun()
            
            with col2:
                if st.button("üßπ Clear Memory", help="Clear GPU/CPU memory"):
                    clear_cuda_memory(verbose=True)
                    st.success("Memory cleared!")
            
            if st.button("üîÑ Reset All", type="primary", help="Reset entire session"):
                clear_cuda_memory(verbose=True)
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.rerun()
        
        # Advanced Debug Info
        with st.expander("üîß Debug Info"):
            st.write(f"**Phase:** {st.session_state.current_phase}")
            st.write(f"**Iterations:** {st.session_state.iteration_count}")
            st.write(f"**Max Reached:** {st.session_state.max_iterations_reached}")
            
            if st.session_state.research_progress:
                st.write(f"**Progress Cached:** ‚úÖ ({st.session_state.research_progress.get('search_count', 0)} searches)")
            else:
                st.write(f"**Progress Cached:** ‚ùå")
            
            st.write(f"**Stream Timeout:** {os.environ.get('AGENT_STREAM_TIMEOUT_S', '300')}s")
            st.write(f"**Model Timeout:** {os.environ.get('OLLAMA_TIMEOUT_S', '120')}s")
            st.write(f"**Search Timeout:** {os.environ.get('TAVILY_SEARCH_TIMEOUT_S', '30')}s")
            
            if st.checkbox("Show Raw Debug Data"):
                st.json({
                    "todos": st.session_state.todos,
                    "step_history_count": len(st.session_state.step_history),
                    "subagent_activity_count": len(st.session_state.subagent_activity),
                    "agent_files": list(st.session_state.agent_files.keys()),
                })


def render_input_phase():
    """Render the query input phase."""
    st.markdown("Ask any research question and the deep agent will analyze, research, and synthesize a comprehensive report.")
    
    # Query input
    query = st.chat_input("What would you like to research?")
    
    if query:
        st.session_state.research_query = query
        st.session_state.messages.append({"role": "user", "content": query})
        st.session_state.current_phase = "research"
        st.rerun()
    
    # Display previous messages if any
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])


def process_agent_event(event: Dict[str, Any]):
    """Process a streaming event from the agent and update UI state."""
    for key, value in event.items():
        # Track todos
        if key == "write_todos" or "todos" in str(value).lower():
            if isinstance(value, dict) and "todos" in value:
                st.session_state.todos = value["todos"]
        
        # Track file writes
        if key == "write_file" or "file" in str(key).lower():
            if isinstance(value, dict):
                filename = value.get("filename", value.get("path", "unknown"))
                content = value.get("content", "")
                st.session_state.agent_files[filename] = content
                
                # Check for final report
                if "final_report" in filename.lower():
                    st.session_state.final_report = content
        
        # Track sub-agent spawning
        if key == "task" or "subagent" in str(key).lower():
            st.session_state.subagent_activity.append({
                "agent": value.get("agent_name", "research-agent"),
                "action": "spawned",
                "query": str(value.get("input", ""))[:200],
                "timestamp": datetime.now().isoformat(),
            })
        
        # Update current step
        st.session_state.step_history.append(st.session_state.current_step or {})
        st.session_state.current_step = {
            "name": key,
            "description": str(value)[:100] if value else "",
            "timestamp": datetime.now().isoformat(),
        }
        
        # Track iterations
        st.session_state.iteration_count += 1
        
        # Check max iterations
        config = get_agent_config()
        max_iter = config["recursion_limit"]
        if st.session_state.iteration_count >= max_iter:
            st.session_state.max_iterations_reached = True
            # Build partial report when max iterations reached
            if not st.session_state.final_report and "research_progress" in st.session_state:
                progress = st.session_state.research_progress
                partial_answer = progress.get("final_answer") or "Research reached maximum iterations before completion."
                st.session_state.final_report = (
                    "# Research Report (Partial)\n\n"
                    f"**Query:** {st.session_state.research_query}\n\n"
                    "## Answer\n\n"
                    f"{partial_answer}\n"
                )


def render_research_phase():
    """Render the research execution phase - auto-starts research immediately."""
    # Auto-start research immediately (no button needed)
    run_research()


def run_research():
    """Execute the deep research agent."""
    agent = get_agent()
    query = st.session_state.research_query
    config = get_agent_config()
    
    with st.status(f"üîç Researching: {query}", expanded=True) as status:
        st.write(f"‚è≥ Using model: **{config['model']}** (may take 30-60 seconds per step)")
        
        # Create placeholders for live updates
        progress_placeholder = st.empty()
        stats_placeholder = st.empty()
        event_log = st.expander("üìä Event Log (Debug)", expanded=False)
        content_display = st.empty()
        
        # Initial state matching AgentState TypedDict
        initial_state = {
            "messages": [("human", query)],
            "research_findings": [],
            "iteration_count": 0
        }
        
        max_retries = 3
        retry_count = 0
        search_count = 0
        think_count = 0
        
        # Auto-generate initial task list (restore from progress if available)
        if "todos" in st.session_state.research_progress:
            st.session_state.todos = st.session_state.research_progress["todos"]
        else:
            st.session_state.todos = [
                {"title": "Analyze research question", "status": "in_progress"},
                {"title": "Search for information", "status": "pending"},
                {"title": "Reflect on findings", "status": "pending"},
                {"title": "Synthesize final answer", "status": "pending"},
            ]
        
        # Restore other progress if available
        if "research_progress" in st.session_state:
            search_count = st.session_state.research_progress.get("search_count", 0)
            think_count = st.session_state.research_progress.get("think_count", 0)
            all_content = st.session_state.research_progress.get("all_content", [])
            final_answer = st.session_state.research_progress.get("final_answer", None)
            research_steps = st.session_state.research_progress.get("research_steps", [])
            search_results = st.session_state.research_progress.get("search_results", [])
        else:
            search_count = 0
            think_count = 0
            all_content = []
            final_answer = None
            research_steps = []
            search_results = []
        
        # Initialize termination reason tracking
        st.session_state.termination_reason = None
        
        while retry_count < max_retries:
            try:
                event_count = 0
                search_results = []  # Track search results
                latest_agent_iteration = 0
                
                # Stream agent execution with timeout protection
                stream_timeout_s = float(os.getenv("AGENT_STREAM_TIMEOUT_S", "300"))  # 5 minutes total
                stream_start_time = time.time()
                last_event_time = stream_start_time
                heartbeat_interval = 30  # seconds
                
                for event in agent.stream(initial_state):
                    event_count += 1
                    current_time = time.time()
                    last_event_time = current_time
                    
                    # Check for overall timeout
                    if current_time - stream_start_time > stream_timeout_s:
                        print(f"\n[STREAM_TIMEOUT] Overall stream timeout after {stream_timeout_s}s")
                        st.session_state.termination_reason = f"‚ö†Ô∏è Stream timeout after {stream_timeout_s//60}min {stream_timeout_s%60}s"
                        break
                    
                    # Log all events for debugging
                    with event_log:
                        elapsed = current_time - stream_start_time
                        st.write(f"Event {event_count} (t+{elapsed:.1f}s): {list(event.keys())}")
                    
                    # Process different event types
                    for key, value in event.items():
                        # Update progress display
                        progress_placeholder.info(f"üîÑ Step {event_count}: {key}")
                        
                        # Handle agent node output
                        if key == "agent" and isinstance(value, dict):
                            if isinstance(value.get("iteration_count"), int):
                                latest_agent_iteration = value["iteration_count"]
                                st.session_state.iteration_count = latest_agent_iteration
                                print(f"[STREAM] Updated iteration count to {latest_agent_iteration}")
                            
                            # Capture termination reason from agent state
                            if value.get("termination_reason"):
                                st.session_state.termination_reason = value["termination_reason"]
                                print(f"[STREAM] Captured termination reason: {value['termination_reason']}")
                            
                            messages = value.get("messages", [])
                            for msg in messages:
                                # Capture content for final report
                                if hasattr(msg, 'content') and msg.content:
                                    content = str(msg.content)
                                    all_content.append(content)
                                    
                                    # FALLBACK: Try to parse various text output formats as final answer
                                    # Some models output text instead of making proper tool calls
                                    # Always try to extract and keep the longest/best answer
                                    extracted = None
                                    
                                    # Try JSON format: {"answer": "..."}
                                    if '"answer"' in content:
                                        try:
                                            import json
                                            parsed = json.loads(content)
                                            if isinstance(parsed, dict) and 'answer' in parsed:
                                                extracted = parsed['answer']
                                        except (json.JSONDecodeError, TypeError):
                                            pass
                                    
                                    # Try text format: - Tool: submit_final_answer\n- Arguments:\n  - answer: ...
                                    if extracted is None and 'submit_final_answer' in content and 'answer:' in content:
                                        try:
                                            import re
                                            # Match various formats the model might use
                                            match = re.search(r'answer:\s*\*?\*?(.+?)(?:\n\s*-\s*completed_tasks:|$)', content, re.DOTALL | re.IGNORECASE)
                                            if match:
                                                extracted = match.group(1).strip().strip('"\'*')
                                        except Exception:
                                            pass
                                    
                                    # Try markdown format: contains ### or ## headings and has substantial content
                                    if extracted is None and ('###' in content or '## ' in content) and len(content) > 300:
                                        extracted = content.strip()
                                    
                                    # Keep the longest extracted answer (better quality)
                                    if extracted and len(extracted) > 200:
                                        if final_answer is None or len(extracted) > len(final_answer):
                                            final_answer = extracted
                                            st.write(f"üìù Captured answer ({len(extracted)} chars)")
                                            st.session_state.todos[3]["status"] = "in_progress"
                                    
                                    # Update task: analyzing complete
                                    if st.session_state.todos[0]["status"] == "in_progress":
                                        st.session_state.todos[0]["status"] = "complete"
                                
                                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                    for tc in msg.tool_calls:
                                        tool_name = tc.get('name', 'unknown')
                                        tool_args = tc.get('args', {})
                                        
                                        # Track tavily search
                                        if tool_name == "tavily_search":
                                            search_count += 1
                                            search_query = tool_args.get('query', '')
                                            st.write(f"üîç Search #{search_count}: {search_query}")
                                            st.session_state.todos[1]["status"] = "in_progress"
                                            research_steps.append({
                                                "type": "search",
                                                "step": event_count,
                                                "query": search_query,
                                                "result": None  # Will be filled by tool result
                                            })
                                        
                                        # Track think tool
                                        if tool_name == "think_tool":
                                            think_count += 1
                                            reflection = tool_args.get('reflection', '')
                                            st.write(f"üß† Think #{think_count}: {reflection[:200]}...")
                                            st.session_state.todos[2]["status"] = "in_progress"
                                            research_steps.append({
                                                "type": "reflection",
                                                "step": event_count,
                                                "content": reflection
                                            })
                                        
                                        # Track submit_final_answer - capture the answer even if rejected
                                        if tool_name == "submit_final_answer":
                                            st.write(f"üìù Submitting final answer...")
                                            st.session_state.todos[3]["status"] = "in_progress"
                                            # Capture the submitted answer as a fallback
                                            submitted_answer = tool_args.get('answer', '')
                                            if submitted_answer and (final_answer is None or len(submitted_answer) > len(final_answer or '')):
                                                final_answer = submitted_answer
                                
                                # Update stats and persist progress
                                stats_placeholder.info(f"üìä Searches: {search_count} | Reflections: {think_count} | Events: {event_count}")
                                
                                # Persist progress to prevent loss on refresh
                                st.session_state.research_progress = {
                                    "search_count": search_count,
                                    "think_count": think_count,
                                    "all_content": all_content,
                                    "final_answer": final_answer,
                                    "research_steps": research_steps,
                                    "todos": st.session_state.todos,
                                    "iteration_count": latest_agent_iteration
                                }
                                
                                # Check for early termination conditions
                                if st.session_state.early_termination_enabled:
                                    if (search_count >= 10 and think_count >= 3 and 
                                        final_answer and len(final_answer) > 800):
                                        print(f"\n[EARLY_TERMINATION] Quality threshold met: {search_count} searches, {think_count} thinks, {len(final_answer)} char answer")
                                        st.session_state.early_termination_triggered = True
                                        if not st.session_state.termination_reason:
                                            st.session_state.termination_reason = f"‚úÖ Early termination - quality threshold met ({search_count} searches, {think_count} reflections)"
                                        break
                        
                        # Handle tools node output
                        if key == "tools" and isinstance(value, dict):
                            if isinstance(value.get("iteration_count"), int):
                                latest_agent_iteration = value["iteration_count"]
                                st.session_state.iteration_count = latest_agent_iteration
                            messages = value.get("messages", [])
                            for msg in messages:
                                if hasattr(msg, 'content') and msg.content:
                                    tool_result = str(msg.content)
                                    
                                    # Check if this is the accepted final answer
                                    if 'FINAL_ANSWER_ACCEPTED' in tool_result:
                                        st.success("‚úÖ Final answer accepted!")
                                        # Extract the answer from the tool result
                                        if '---ANSWER---' in tool_result:
                                            final_answer = tool_result.split('---ANSWER---')[1].strip()
                                            content_display.markdown(f"### üìù Final Answer\n\n{final_answer[:2000]}...")
                                        else:
                                            final_answer = tool_result
                                        st.session_state.todos[3]["status"] = "complete"
                                    elif 'SUBMISSION_REJECTED' in tool_result:
                                        st.warning(f"‚ö†Ô∏è Submission rejected: {tool_result[:200]}...")
                                    elif 'Reflection recorded:' in tool_result:
                                        # This is a think_tool result, already tracked
                                        pass
                                    else:
                                        # This is likely a search result - attach to last search step
                                        content_preview = tool_result[:200]
                                        st.write(f"üìÑ Result: {content_preview}...")
                                        # Update the last search step with its result
                                        for step in reversed(research_steps):
                                            if step["type"] == "search" and step["result"] is None:
                                                step["result"] = tool_result
                                                break
                                    
                                    search_results.append(tool_result)
                        
                        # Update step tracking
                        st.session_state.step_history.append(st.session_state.current_step or {})
                        st.session_state.current_step = {
                            "name": key,
                            "description": str(value)[:100] if value else "",
                            "timestamp": datetime.now().isoformat(),
                        }
                    
                    # Check max iterations
                    if latest_agent_iteration >= config["recursion_limit"]:
                        st.session_state.max_iterations_reached = True
                        if not st.session_state.termination_reason:
                            st.session_state.termination_reason = f"‚ö†Ô∏è Maximum iterations reached ({config['recursion_limit']})"
                        st.warning("Maximum iterations reached, stopping...")
                        break
                    
                    # Heartbeat check - if no events for too long, something may be stuck
                    if current_time - last_event_time > heartbeat_interval:
                        st.warning(f"‚ö†Ô∏è No events for {heartbeat_interval}s, agent may be stuck...")
                        # Continue for now, but this indicates a potential issue
                
                # Mark all tasks complete
                for todo in st.session_state.todos:
                    todo["status"] = "complete"
                
                # Store research steps in session state for display
                st.session_state.research_steps = research_steps
                
                # Clear progress cache on successful completion
                if "research_progress" in st.session_state:
                    del st.session_state.research_progress
                
                # Build final report from the accepted final answer
                # Look for FINAL_ANSWER_ACCEPTED in search_results (tool outputs)
                accepted_answer = None
                for result in search_results:
                    if 'FINAL_ANSWER_ACCEPTED' in result and '---ANSWER---' in result:
                        accepted_answer = result.split('---ANSWER---')[1].strip()
                        break
                
                # Fall back to final_answer variable or longest content
                if accepted_answer:
                    final_answer = accepted_answer
                elif final_answer is None and all_content:
                    # Find the longest content as the likely final answer
                    final_answer = max(all_content, key=len) if all_content else "No answer generated."
                
                # Build comprehensive fallback report from search results and reflections
                if final_answer is None:
                    # Extract structured content from search results and reflections
                    search_summaries = []
                    reflection_summaries = []
                    
                    for result in search_results:
                        if 'Title:' in result and 'URL:' in result:
                            lines = result.split('\n')
                            title = next((line.replace('Title: ', '') for line in lines if line.startswith('Title:')), 'Unknown')
                            url = next((line.replace('URL: ', '') for line in lines if line.startswith('URL:')), '')
                            content_line = next((line.replace('Content: ', '') for line in lines if line.startswith('Content:')), '')
                            if content_line and len(content_line) > 50:
                                # Keep full content, only truncate if extremely long (>2000 chars)
                                if len(content_line) > 2000:
                                    content_display = content_line[:2000] + "..."
                                else:
                                    content_display = content_line
                                search_summaries.append(f"**{title}** ({url})\n{content_display}")
                    
                    for step in research_steps:
                        if step.get('type') == 'reflection' and step.get('content'):
                            # Keep full reflection content, only truncate if extremely long (>1500 chars)
                            content = step['content']
                            if len(content) > 1500:
                                reflection_summaries.append(content[:1500] + "...")
                            else:
                                reflection_summaries.append(content)
                    
                    # Build comprehensive answer from extracted content
                    if search_summaries or reflection_summaries:
                        answer_parts = [f"# Analysis of: {st.session_state.research_query}\n"]
                        
                        if search_summaries:
                            answer_parts.append("## Key Research Findings\n\n")
                            for i, summary in enumerate(search_summaries[:7], 1):  # Show up to 7 searches
                                answer_parts.append(f"{i}. {summary}\n\n")
                        
                        if reflection_summaries:
                            answer_parts.append("## Analysis & Insights\n\n")
                            for i, reflection in enumerate(reflection_summaries[:5], 1):  # Show up to 5 reflections
                                answer_parts.append(f"**Insight {i}:** {reflection}\n\n")
                        
                        answer_parts.append(f"\n---\n\n*Research completed with {search_count} searches and {think_count} reflections. Full content preserved from all sources.*")
                        final_answer = ''.join(answer_parts)
                    else:
                        final_answer = max(all_content, key=len) if all_content else "Research completed but no final answer was generated. Check the event log for details."
                
                if final_answer:
                    # Build comprehensive report
                    report = f"# Research Report\n\n"
                    report += f"**Query:** {st.session_state.research_query}\n\n"
                    report += f"**Research Stats:** {search_count} searches, {think_count} reflections\n\n"
                    
                    # Add termination reason if research ended partially
                    if st.session_state.termination_reason:
                        report += f"**Completion Status:** {st.session_state.termination_reason}\n\n"
                    
                    # Check if this is a structured answer or needs formatting
                    if final_answer.startswith('# Analysis of:'):
                        report += final_answer  # Already well-formatted
                    else:
                        report += f"## Answer\n\n{final_answer}\n\n"
                    
                    if search_results:
                        # Extract URLs from search results (excluding the final answer result)
                        urls_found = []
                        for result in search_results:
                            if "URL:" in result and 'FINAL_ANSWER_ACCEPTED' not in result:
                                for line in result.split('\n'):
                                    if 'URL:' in line:
                                        urls_found.append(line.strip())
                        if urls_found:
                            report += f"## Sources Consulted ({len(urls_found)} URLs found)\n\n"
                            for i, url in enumerate(urls_found[:15], 1):
                                report += f"{i}. {url}\n"
                    
                    st.session_state.final_report = report
                    st.success(f"‚úÖ Research complete! {search_count} searches, {think_count} reflections.")
                else:
                    st.session_state.final_report = "No final answer was generated. The agent may not have used submit_final_answer tool properly."
                    st.warning("‚ö†Ô∏è No final answer captured. The agent should use submit_final_answer tool.")
                
                # Mark as complete
                st.session_state.current_phase = "complete"
                status.update(label="‚úÖ Research Complete!", state="complete", expanded=False)
                break  # Success - exit retry loop
                
            except Exception as e:
                error_msg = str(e)
                if "empty" in error_msg.lower() and retry_count < max_retries - 1:
                    retry_count += 1
                    st.warning(f"‚ö†Ô∏è Model returned empty response, retrying ({retry_count}/{max_retries})...")
                    continue
                else:
                    st.error(f"Error during research: {error_msg}")
                    import traceback
                    st.code(traceback.format_exc())
                    # Build emergency partial report from any available data
                    partial_answer = None
                    if final_answer:
                        partial_answer = final_answer
                    elif all_content:
                        partial_answer = max(all_content, key=len)
                    elif "research_progress" in st.session_state:
                        progress = st.session_state.research_progress
                        if progress.get("all_content"):
                            partial_answer = max(progress["all_content"], key=len)
                        elif progress.get("research_steps"):
                            # Build answer from cached research steps
                            cached_searches = [s for s in progress["research_steps"] if s.get("type") == "search"]
                            cached_reflections = [s for s in progress["research_steps"] if s.get("type") == "reflection"]
                            
                            if cached_searches or cached_reflections:
                                parts = [f"Partial research results for: {st.session_state.research_query}\n\n"]
                                if cached_searches:
                                    parts.append(f"Completed {len(cached_searches)} searches:\n")
                                    for search in cached_searches[:3]:
                                        parts.append(f"- {search.get('query', 'Unknown query')}\n")
                                if cached_reflections:
                                    parts.append(f"\nAnalysis insights ({len(cached_reflections)} reflections):\n")
                                    for refl in cached_reflections[:2]:
                                        content = refl.get('content', '')[:200]
                                        parts.append(f"- {content}...\n")
                                partial_answer = ''.join(parts)
                    else:
                        partial_answer = "Research failed before any answer could be captured. Check the event log and traceback above."
                    
                    # Add termination reason to error report if available
                    termination_info = ""
                    if st.session_state.termination_reason:
                        termination_info = f"**Termination Reason:** {st.session_state.termination_reason}\n\n"
                    
                    st.session_state.final_report = (
                        "# Research Report (Error Recovery)\n\n"
                        f"**Query:** {st.session_state.research_query}\n\n"
                        f"{termination_info}"
                        "## Partial Results\n\n"
                        f"{partial_answer}\n\n"
                        "---\n\n"
                        "**Note:** Research was interrupted due to an error, but partial results were recovered.\n\n"
                        f"**Technical Details:** {error_msg}\n"
                    )
                    st.session_state.current_phase = "complete"  # Still transition to show what we have
                    status.update(label="‚ùå Research Failed", state="error", expanded=True)
                    break
        
        # Always rerun to show results, even on error
        st.rerun()


def render_completion_phase():
    """Render the results and final report."""
    st.markdown("## üìä Research Results")
    
    # Show the original query
    st.markdown(f"**Query:** {st.session_state.research_query}")
    
    # Max iterations warning
    if st.session_state.max_iterations_reached:
        st.warning("‚ö†Ô∏è **Note:** Maximum iterations were reached during research. Results may be incomplete.")
    
    st.divider()
    
    # Display final report prominently
    if st.session_state.final_report:
        st.markdown(st.session_state.final_report)
    elif "/final_report.md" in st.session_state.agent_files:
        st.markdown(st.session_state.agent_files["/final_report.md"])
    else:
        st.error("‚ùå No final report was generated.")
        st.info("The agent may not have completed properly. Check the progress history below for details.")
    
    st.divider()
    
    # Research statistics
    search_steps = [s for s in st.session_state.research_steps if s["type"] == "search"]
    reflection_steps = [s for s in st.session_state.research_steps if s["type"] == "reflection"]
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total Steps", st.session_state.iteration_count)
    with col2:
        st.metric("Searches", len(search_steps))
    with col3:
        st.metric("Reflections", len(reflection_steps))
    
    # Research work in progress - Searches
    if search_steps:
        with st.expander(f"üîç Web Searches ({len(search_steps)})", expanded=True):
            for i, step in enumerate(search_steps, 1):
                with st.expander(f"Search {i}: {step['query'][:60]}{'...' if len(step['query']) > 60 else ''}", expanded=False):
                    st.markdown(f"**Query:** {step['query']}")
                    if step.get('result'):
                        st.markdown("**Results:**")
                        # Parse and display results nicely
                        result = step['result']
                        # Extract title and URL if present
                        if 'Title:' in result and 'URL:' in result:
                            lines = result.split('\n')
                            for line in lines:
                                if line.startswith('Title:'):
                                    st.markdown(f"üìÑ **{line.replace('Title:', '').strip()}**")
                                elif line.startswith('URL:'):
                                    url = line.replace('URL:', '').strip()
                                    st.markdown(f"üîó [{url}]({url})")
                                elif line.startswith('Content:'):
                                    content = line.replace('Content:', '').strip()
                                    st.caption(content[:500] + "..." if len(content) > 500 else content)
                        else:
                            st.caption(result[:800] + "..." if len(result) > 800 else result)
                    else:
                        st.caption("No results captured")
    
    # Research work in progress - Reflections
    if reflection_steps:
        with st.expander(f"üß† Agent Reflections ({len(reflection_steps)})", expanded=False):
            for i, step in enumerate(reflection_steps, 1):
                with st.expander(f"Reflection {i}", expanded=False):
                    st.markdown(step.get('content', 'No content'))
    
    # Raw progress history (collapsed by default)
    with st.expander("üìú Raw Progress History", expanded=False):
        if st.session_state.step_history:
            for i, step in enumerate(st.session_state.step_history):
                if step:
                    step_name = step.get('name', 'Unknown')
                    step_desc = step.get('description', '')[:100]
                    st.markdown(f"**Step {i+1}:** {step_name}")
                    if step_desc:
                        st.caption(step_desc)
        else:
            st.info("No step history recorded.")
    
    # Display agent files if any
    if st.session_state.agent_files:
        with st.expander("üìÅ Agent Files", expanded=False):
            for filename, content in st.session_state.agent_files.items():
                st.markdown(f"**{filename}**")
                st.code(content[:1000] if len(content) > 1000 else content, language="markdown")
    
    st.divider()
    
    # Action buttons
    col1, col2 = st.columns(2)
    with col1:
        if st.session_state.final_report:
            st.download_button(
                "üì• Download Report",
                data=st.session_state.final_report,
                file_name="research_report.md",
                mime="text/markdown"
            )
    with col2:
        if st.button("üîÑ New Research"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()


def main():
    """Main application entry point."""
    initialize_session_state()
    render_sidebar()
    
    st.title("üîç Local Deep Researcher")
    st.caption("Powered by LangChain DeepAgents + Ollama")
    
    # Phase routing
    if st.session_state.current_phase == "input":
        render_input_phase()
    elif st.session_state.current_phase == "research":
        render_research_phase()
    elif st.session_state.current_phase == "complete":
        render_completion_phase()


if __name__ == "__main__":
    main()
