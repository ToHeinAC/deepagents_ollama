# Generated by Antigravity [Forge: Gemini 3.0] | Spec: [Architect: Opus 4.5]
"""Research Tools.

This module provides search and content processing utilities for the research agent,
using Tavily for URL discovery and fetching full webpage content.
"""

import os
import re
import httpx
from langchain_core.tools import InjectedToolArg, tool
from markdownify import markdownify
from tavily import TavilyClient
from typing_extensions import Annotated, Literal
from dotenv import load_dotenv

# Import memory management utilities
try:
    from memory_utils import clear_cuda_memory
except ImportError:
    # Fallback if module not found
    def clear_cuda_memory(verbose=True):
        import gc
        gc.collect()
        if verbose:
            print("[MEMORY] Garbage collection completed (fallback)")

# Load environment variables
load_dotenv()

# Initialize Tavily client
tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))


def fetch_webpage_content(url: str, timeout: float = 10.0) -> str:
    """Fetch and convert webpage content to markdown.

    Args:
        url: URL to fetch
        timeout: Request timeout in seconds

    Returns:
        Webpage content as markdown
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        response = httpx.get(url, headers=headers, timeout=timeout)
        response.raise_for_status()
        return markdownify(response.text)
    except Exception as e:
        return f"Error fetching content from {url}: {str(e)}"


@tool(parse_docstring=True)
def tavily_search(
    query: str,
    max_results: Annotated[int, InjectedToolArg] = 1,
    topic: Annotated[
        Literal["general", "news", "finance"], InjectedToolArg
    ] = "general",
) -> str:
    """Search the web for information on a given query.

    Uses Tavily to discover relevant URLs, then fetches and returns full webpage content as markdown.

    Args:
        query: Search query to execute
        max_results: Maximum number of results to return (default: 1)
        topic: Topic filter - 'general', 'news', or 'finance' (default: 'general')

    Returns:
        Formatted search results with full webpage content
    """
    # Use Tavily to search
    response = tavily_client.search(
        query,
        max_results=max_results,
        topic=topic,
    )

    # Fetch full content for each URL
    # Process results
    content = []
    for result in response.get("results", []):
        title = result.get("title", "No Title")
        url = result.get("url", "")
        raw_content = result.get("content", "")
        
        # Limit content length for local models
        if len(raw_content) > 2000:
            raw_content = raw_content[:2000] + "... (truncated)"
            
        content.append(f"Title: {title}\nURL: {url}\nContent: {raw_content}\n")
        
    # Clear memory after search to prevent VRAM accumulation
    clear_cuda_memory(verbose=True)
    
    return "\n---\n".join(content)


@tool(parse_docstring=True)
def think_tool(reflection: str) -> str:
    """Tool for strategic reflection on research progress and decision-making.

    Use this tool after each search to analyze results and plan next steps systematically.
    This creates a deliberate pause in the research workflow for quality decision-making.

    When to use:
    - After receiving search results: What key information did I find?
    - Before deciding next steps: Do I have enough to answer comprehensively?
    - When assessing research gaps: What specific information am I still missing?
    - Before concluding research: Can I provide a complete answer now?

    Reflection should address:
    1. Analysis of current findings - What concrete information have I gathered?
    2. Gap assessment - What crucial information is still missing?
    3. Quality evaluation - Do I have sufficient evidence/examples for a good answer?
    4. Strategic decision - Should I continue searching or provide my answer?

    Args:
        reflection: Your detailed reflection on research progress, findings, gaps, and next steps

    Returns:
        Confirmation that reflection was recorded for decision-making
    """
    # Clear memory after reflection to free resources
    clear_cuda_memory(verbose=True)
    
    return f"Reflection recorded: {reflection}"


def _count_words(text: str) -> int:
    """Count words in text."""
    return len(text.split())

def _count_urls(text: str) -> int:
    """Count unique URLs in text (http:// or https://).
    
    Matches URLs in various formats including:
    - Plain URLs: https://example.com
    - Markdown links: [text](https://example.com)
    - Inline citations: (https://example.com)
    - Bracketed: [https://example.com]
    - With trailing punctuation: https://example.com.
    """
    # Match URLs - be permissive, capture everything after https?://
    # until we hit whitespace or certain delimiters
    urls = re.findall(r'https?://[^\s<>\"\']+', text)
    
    # Clean trailing punctuation that might be captured
    cleaned_urls = []
    for url in urls:
        # Remove trailing punctuation that's likely not part of the URL
        while url and url[-1] in ')],.:;!?\'"':
            url = url[:-1]
        if url:  # Only add non-empty URLs
            cleaned_urls.append(url)
    
    return len(set(cleaned_urls))

def _validate_final_answer(answer: str) -> tuple[bool, str]:
    """Validate that the final answer meets quality requirements.
    
    Requirements:
    - At least 300 words
    - At least 5 unique source URLs
    
    Returns:
        Tuple of (is_valid, error_message)
    """
    word_count = _count_words(answer)
    url_count = _count_urls(answer)
    
    errors = []
    
    if word_count < 300:
        errors.append(f"Answer has only {word_count} words (minimum: 300)")
    
    if url_count < 5:
        errors.append(f"Answer has only {url_count} source URLs (minimum: 5)")
    
    if errors:
        return False, "; ".join(errors)
    
    return True, f"Valid: {word_count} words, {url_count} source URLs"


@tool(parse_docstring=True)
def submit_final_answer(
    answer: str,
    completed_tasks: str,
) -> str:
    """Submit your final comprehensive answer to conclude the research session.
    
    CRITICAL: Only use this tool when ALL of the following conditions are met:
    1. You have completed ALL tasks in your research plan
    2. Your answer has AT LEAST 300 words
    3. Your answer includes AT LEAST 5 source URLs (https://...)
    4. You have thoroughly researched the topic from multiple angles
    
    SOURCE REQUIREMENT:
    Include the full URL for each source you cite. Any citation format is acceptable
    as long as the source URL is visible.
    
    If your answer does not meet these requirements, the submission will be REJECTED
    and you must continue researching.
    
    Args:
        answer: Your complete, well-structured final answer with source URLs.
                Must be at least 300 words with at least 5 source URLs.
        completed_tasks: A brief summary of all research tasks you completed
                        (e.g., "1. Searched recent news, 2. Found expert analysis, 
                        3. Gathered historical context, 4. Collected statistics, 
                        5. Explored alternative perspectives")
    
    Returns:
        Either confirmation of successful submission or rejection with reasons
    """
    print(f"[SUBMIT] Validating final answer ({len(answer)} chars)...")
    is_valid, message = _validate_final_answer(answer)
    
    if not is_valid:
        print(f"[SUBMIT] REJECTED: {message}")
        rejection_msg = f"SUBMISSION_REJECTED: {message}.\n\n"
        rejection_msg += "IMPORTANT: You must include the full URL (https://...) for each source.\n"
        rejection_msg += "Any citation format is fine, but the URL must be visible.\n\n"
        rejection_msg += "Fix your answer and submit again."
        return rejection_msg
    
    # Format the final answer with metadata
    word_count = _count_words(answer)
    url_count = _count_urls(answer)
    
    print(f"[SUBMIT] ACCEPTED: {word_count} words, {url_count} URLs")
    
    # Clear memory before returning final answer
    clear_cuda_memory(verbose=True)
    
    return f"""FINAL_ANSWER_ACCEPTED
---METADATA---
Word Count: {word_count}
Sources: {url_count}
Completed Tasks: {completed_tasks}
---ANSWER---
{answer}"""
